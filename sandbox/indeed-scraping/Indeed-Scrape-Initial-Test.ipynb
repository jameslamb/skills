{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URL = \"https://www.indeed.com/jobs?q=software+engineer\"\n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Software Engineer',\n",
       " u'Software Engineer (full stack node.js)',\n",
       " u'Embedded Software Developer',\n",
       " u'Software API Engineer',\n",
       " u'Software Engineering Internship (Summer 2018)',\n",
       " u'Software Development Engineer I',\n",
       " u'Software Dev Engineer I',\n",
       " u'Software Engineer',\n",
       " u'Java Systems Engineer',\n",
       " u'Factory Software Integration Support Engineer',\n",
       " u'Jr. Software Engineer (REF7034T)',\n",
       " u'Software Engineer',\n",
       " u'Software Engineer - New College Grad',\n",
       " u'Software Engineer',\n",
       " u'Software Developer',\n",
       " u'Software Engineer (node.js)']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "  jobs = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "      for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "        jobs.append(a[\"title\"])\n",
    "  return(jobs)\n",
    "\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Indeed Prime',\n",
       " u'Pluralsight',\n",
       " u'Alveo Technologies',\n",
       " u'Nevro Corporation',\n",
       " u'WePay',\n",
       " u'Amazon.com',\n",
       " u'Oath Inc',\n",
       " u'Tesla',\n",
       " u'Wells Fargo',\n",
       " u'Tesla',\n",
       " u'Visa',\n",
       " u'Microsoft',\n",
       " u'Proofpoint',\n",
       " u'Cisco',\n",
       " u'BeaconMD',\n",
       " u'Pluralsight']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup):\n",
    "  companies = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "    if len(company) > 0:\n",
    "      for b in company:\n",
    "        companies.append(b.text.strip())\n",
    "    else:\n",
    "      sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "      for span in sec_try:\n",
    "            companies.append(span.text.strip())\n",
    "            \n",
    "  return(companies)\n",
    " \n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'San Francisco, CA',\n",
       " u'South Jordan, UT',\n",
       " u'Alameda, CA 94501',\n",
       " u'Redwood City, CA 94065',\n",
       " u'Redwood City, CA',\n",
       " u'Palo Alto, CA',\n",
       " u'Sunnyvale, CA',\n",
       " u'Fremont, CA',\n",
       " u'Fremont, CA 94537 (Cabrillo area)',\n",
       " u'Fremont, CA',\n",
       " u'Foster City, CA',\n",
       " u'Palo Alto, CA',\n",
       " u'Sunnyvale, CA 94089',\n",
       " u'Milpitas, CA',\n",
       " u'Guaynabo, PR 00968',\n",
       " u'Boston, MA']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "  locations = []\n",
    "  spans = soup.findAll(\"span\", attrs={\"class\": \"location\"})\n",
    "  for span in spans:\n",
    "    locations.append(span.text)\n",
    "  return(locations)\n",
    "\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "  salaries = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    try:\n",
    "      salaries.append(div.find(\"nobr\").text)\n",
    "    except:\n",
    "      try:\n",
    "        div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n",
    "        div_three = div_two.find(\"div\")\n",
    "        salaries.append(div_three.text.strip())\n",
    "      except:\n",
    "        salaries.append(\"Nothing_found\")\n",
    "  return(salaries)\n",
    "extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'How Indeed Prime Works Apply to Prime in 5 minutes. Apply to 100+ top companies with 1 simple application to Indeed Prime....',\n",
       " u\"Continuous Delivery - teams independently ship code to prod every day. We do this through the tech industry's leading learning platform for serious Developer,...\",\n",
       " u'Your primary responsibility would be building to develop embedded software for new products and prototypes. Define and develop embedded software architecture...',\n",
       " u'Develops software in a regulated environment in accordance with internal operating procedures and external standards and regulations....',\n",
       " u'Our stack is primarily based on Python and Java. 500 fastest-growing private companies list before its December 2017 acquisition by JPMorgan Chase & Co., and...',\n",
       " u\"Proficiency in, at least, one modern programming language such as C, C++, Java, or Perl. Join us, and you'll be taking part in changing the future of everyday...\",\n",
       " u'You will be coding in Java and/or C++ on Unix platform to help build the next generation backend for Yahoo Mail....',\n",
       " u'Strong Core Java Experience with Expertise in enterprise Java technology eco-system including Spring Boot, JPA/Spring Data, maven, JUnit....',\n",
       " u'Develop, maintain and support COTLS Java application. Wells Fargo Wholesale Loan Services Technology division is seeking a Java/J2EE engineer to provide...',\n",
       " u'This position will manage day to day factory software in a highly automated car or battery facility. The Factory Software Integration Team is seeking highly...',\n",
       " u'0-2+ years of Java experience is required. 0-2+ years of professional experience developing object oriented software....',\n",
       " u'To realize them, we are aggressively looking for passionate software engineers to join our teams in Palo Alto, San Francisco, Redmond, Boston or Prague....',\n",
       " u'We are looking for individuals that are as passionate as we are about building great software. Proofpoint is looking for excellent software engineers to join...',\n",
       " u'Develop embedded software for switches, routers within IOS-XE. In this role you will participate on a project team of engineers involved in the development of...',\n",
       " u'Company stock, health insurance, paid time off, on-site gym equipment, snacks, penthouse office with ocean view....',\n",
       " u\"Continuous Delivery - teams independently ship code to prod every day. We do this through the tech industry's leading learning platform for serious Developer,...\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "  summaries = []\n",
    "  spans = soup.findAll(\"span\", attrs={\"class\": \"summary\"})\n",
    "  for span in spans:\n",
    "    summaries.append(span.text.strip())\n",
    "  return(summaries)\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_results_per_city = 100\n",
    "city_set = [\"New+York\",\"Chicago\",\"San+Francisco\", \"Austin\"]\n",
    "columns = [\"city\", \"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scraping code:\n",
    "for city in city_set:\n",
    "  for start in range(0, max_results_per_city, 10):\n",
    "      page = requests.get(\"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=\" + str(city) + \"&start=\" + str(start))\n",
    "      time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "      soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "      for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}): \n",
    "        #specifying row num for index of job posting in dataframe\n",
    "        num = (len(sample_df) + 1) \n",
    "        #creating an empty list to hold the data for each posting\n",
    "        job_post = [] \n",
    "        #append city name\n",
    "        job_post.append(city) \n",
    "        #grabbing job title\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            job_post.append(a[\"title\"]) \n",
    "        #grabbing company name\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"}) \n",
    "        if len(company) > 0: \n",
    "            for b in company:\n",
    "                job_post.append(b.text.strip()) \n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                job_post.append(span.text) \n",
    "        #grabbing location name\n",
    "        c = div.findAll(\"span\", attrs={\"class\": \"location\"}) \n",
    "        for span in c: \n",
    "            job_post.append(span.text) \n",
    "        #grabbing summary text\n",
    "        d = div.findAll(\"span\", attrs={\"class\": \"summary\"}) \n",
    "        for span in d:\n",
    "            job_post.append(span.text.strip()) \n",
    "        #grabbing salary\n",
    "        try:\n",
    "            job_post.append(div.find(\"nobr\").text) \n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"}) \n",
    "                div_three = div_two.find(\"div\") \n",
    "                job_post.append(div_three.text.strip())\n",
    "            except:\n",
    "                job_post.append(\"Nothing_found\") \n",
    "        #appending list of job post info to dataframe at index num\n",
    "        sample_df.loc[num] = job_post\n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "sample_df.to_csv(\"scraped-jobs.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_job(jobId):\n",
    "    URL = \"https://www.indeed.com/jobs?q=sw&vjk=\" + str(jobId)\n",
    "    #conducting a request of the stated URL above:\n",
    "    page = requests.get(URL)\n",
    "    #specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    #printing soup in a more structured tree format that makes for easier reading\n",
    "    #print(soup.prettify())\n",
    "\n",
    "extract_job(\"febf687db2ce1f38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
