Uber 82--Engineering-Manager--Hadoop-Hdfs---Palo-Alto--Ca---Uber---Uber.Txt




uber is currently looking for an experienced engineering manager to lead our hdfs development effort. based in palo alto, the hdfs analytics storage team is responsible for the primary storage and storage access layers for all of uber's analytics data. the team's mission is to provide access to scalable, resilient, secure, efficient and highly performant storage systems for all of uber's bi, analytics and ml applications. come lead the next generation hdfs and analytical storage systems and help us solve upcoming challenges include scaling to larger volumes of data and number of objects, namenode scalability, federated clusters, erasure coding, tiered storage, data freshness, data protection, multi-tenancy, slas, acls, and storage cost efficiency.
attract, hire, mentor and retain the best tech talent
build and lead a team of 10+ engineers with a mix of hadoop committers and infrastructure engineers
develop cross-org partnerships with peer organizations; collaborate and address their data storage requirements
influence and guide strategy, execution and innovation for all aspects of big data storage at uber
engage with hdfs open source community to understand existing work and influence future roadmap; represent uber via talks at conferences and blog posts
3+ years of management experience scaling and managing 5+ person teams with a track record of delivering results while growing/mentoring engineers on your team
experience going through the full software cycle of requirements, design, coding/testing best practices and operational excellence in delivering world class software and services
communication and leadership skills, with the ability to initiate and drive processes and projects proactively
solid understanding of distributed storage systems and system fundamentals such as concurrency, multi-threading, locking etc.
be customer obsessed and have the ability to translate customer and technical requirements into detailed engineering plans, architecture and design
give technical feedback and drive quality via code reviews, design reviews and postmortems

under the hood experience with apache hadoop hdfs or similar systems such as apache kudu, apache hbase etc. is a strong plus
experience with highly available/fault tolerant, replicated data storage systems, large scale data processing systems or enterprise/cloud storage systems is also a strong plus

the hdfs analytics storage team is part of the hadoop analytics and infrastructure team. the hadoop analytics and infrastructure team is based in palo alto, seattle and san francisco and is responsible for building the interactive and batch querying systems (based on hive, presto), advanced data processing platforms (based on spark, other data science tools), hadoop observability and security (knox, sentry) and the underlying storage and resource management infrastructure (with hdfs, yarn), for the rest of the company.

we have a small tightly knit team with a diverse set of backgrounds from companies such as facebook, google, cloudera, hortonworks, amazon, microsoft, linkedin, twitter, pinterest, dropbox, other startups and college grads from the top schools. the team is proud to be a part of the open source community in innovating and shaping such exciting technologies as we move forward. uber, as a business, is also growing rapidly, and data at uber is at the heart of almost all products e.g. pricing predictions, uber pool route optimizations, uber eats restaurant recommendations, fraud detection, storage and processing of data collected from autonomous vehicles etc.

by solving these business problems you will not only be helping uber but also have a front row seat to build and innovate the future big data systems and contribute them back to open source. this is an exciting time to be part of the data team at uber. be sure to checkout our
engineering blog
to learn more about the team.

